{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis with Python\n",
    "\n",
    "We will explore the NYC MTA turnstile data set. These data files are from the New York Subway. It tracks the hourly entries and exits to turnstiles (UNIT) by day in the subway system.\n",
    "\n",
    "Here is an [example of what you could do with the data](https://jameskao.me/analyzing-the-nyc-subway-dataset/). James Kao investigates how subway ridership is affected by incidence of rain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "- Download at least 2 weeks worth of [MTA turnstile data](http://web.mta.info/developers/turnstile.html) (You can do this manually or via Python)\n",
    "- Open up a file, use csv reader to read it, make a python dict where there is a key for each (C/A, UNIT, SCP, STATION). These are the first four columns. The value for this key should be a list of lists. Each list in the list is the rest of the columns in a row. For example, one key-value pair should look like\n",
    "\n",
    "\n",
    "        {    ('A002','R051','02-00-00','LEXINGTON AVE'):    \n",
    "             [\n",
    "               ['NQR456', 'BMT', '01/03/2015', '03:00:00', 'REGULAR', '0004945474', '0001675324'],          \n",
    "                 ['NQR456', 'BMT', '01/03/2015', '07:00:00', 'REGULAR', '0004945478', '0001675333'],  \n",
    "                ['NQR456', 'BMT', '01/03/2015', '11:00:00', 'REGULAR', '0004945515', '0001675364'],\n",
    "              ...   \n",
    "         ] \n",
    "        }\n",
    "\n",
    "*Store all the weeks in a data structure of your choosing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161231 file downloaded\n",
      "161224 file downloaded\n",
      "161217 file downloaded\n",
      "161210 file downloaded\n"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "\n",
    "url_template = 'http://web.mta.info/developers/data/nyct/turnstile/turnstile_%s.txt'\n",
    "for  date in ['161231','161224','161217','161210']:\n",
    "    url = url_template % date\n",
    "    wget.download(url)\n",
    "    print(date,'file downloaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv, glob\n",
    "\n",
    "\n",
    "df1 =pd.read_csv(\"turnstile_161210.txt\")\n",
    "df2 =pd.read_csv(\"turnstile_161217.txt\")\n",
    "df3 =pd.read_csv(\"turnstile_161224.txt\")\n",
    "df4 =pd.read_csv(\"turnstile_161231.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def read_csv(file):\n",
    "    turnstile_reading = defaultdict(list)\n",
    "    with open(file,'r') as csv_file:\n",
    "        mta_reader=csv.reader(csv_file)\n",
    "        for i,row in enumerate(mta_reader):\n",
    "            if i==0:\n",
    "                continue\n",
    "                \n",
    "            turnstile_info = tuple(row[:4])\n",
    "            count_reading = row[:4]\n",
    "            turnstile_reading[turnstile_info].append(count_reading)\n",
    "    return turnstile_reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weekly_data_dicts = [read_csv(csvfile) for csvfile in glob.glob('turnstile_*.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_dict = list(weekly_data_dicts[0].items())[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('A002', 'R051', '02-00-00', '59 ST'),\n",
      "  [['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-00', '59 ST']]),\n",
      " (('A002', 'R051', '02-00-01', '59 ST'),\n",
      "  [['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST'],\n",
      "   ['A002', 'R051', '02-00-01', '59 ST']])]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(sample_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "- Let's turn this into a time series.\n",
    "\n",
    " For each key (basically the control area, unit, device address and station of a specific turnstile), have a list again, but let the list be comprised of just the point in time and the cumulative count of entries.\n",
    "\n",
    "This basically means keeping only the date, time, and entries fields in each list. You can convert the date and time into datetime objects -- That is a python class that represents a point in time. You can combine the date and time fields into a string and use the [dateutil](https://dateutil.readthedocs.io/en/stable/) module to convert it into a datetime object.\n",
    "\n",
    "Your new dict should look something like\n",
    " \n",
    "    {    ('A002','R051','02-00-00','LEXINGTON AVE'):    \n",
    "             [\n",
    "                [datetime.datetime(2013, 3, 2, 3, 0), 3788],\n",
    "                [datetime.datetime(2013, 3, 2, 7, 0), 2585],\n",
    "                [datetime.datetime(2013, 3, 2, 12, 0), 10653],\n",
    "                [datetime.datetime(2013, 3, 2, 17, 0), 11016],\n",
    "                [datetime.datetime(2013, 3, 2, 23, 0), 10666],\n",
    "                [datetime.datetime(2013, 3, 3, 3, 0), 10814],\n",
    "                [datetime.datetime(2013, 3, 3, 7, 0), 10229],\n",
    "                ...\n",
    "              ],\n",
    "     ....\n",
    "     }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "def convert_to_time_series(week_data_dict):\n",
    "    time_series = defaultdict(list)\n",
    "    for i, (turnstile,row_data) in enumerate(week_data_dict.items()):\n",
    "        if i%100 == 0:\n",
    "            print('processing turnstile',turnstile)\n",
    "            \n",
    "        for lines, division, datestr, timestr, event, cum_entries, cum_exits in row_data:\n",
    "            timestamp = parse('%sT%s' % (datestr, timestr))\n",
    "            time_series[turnstile].append([timestamp,int(cum_entries)])\n",
    "            \n",
    "    return time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing turnstile ('A002', 'R051', '02-00-00', '59 ST')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 7, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-34c87fa88b38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mweekly_time_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_to_time_series\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweekly_data_dicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-484415dd5bcb>\u001b[0m in \u001b[0;36mconvert_to_time_series\u001b[0;34m(week_data_dict)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'processing turnstile'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mturnstile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdivision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatestr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcum_entries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcum_exits\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mtimestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%sT%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdatestr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mtime_series\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mturnstile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcum_entries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 7, got 4)"
     ]
    }
   ],
   "source": [
    "weekly_time_series = list(map(convert_to_time_series, weekly_data_dicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weekly_time_series' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-07eb1d8b21ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweekly_time_series\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'weekly_time_series' is not defined"
     ]
    }
   ],
   "source": [
    "sample = list(weekly_time_series[0].items())[:5]\n",
    "pprint(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "- These counts are cumulative every n hours. We want total daily entries. \n",
    "\n",
    "Now make it that we again have the same keys, but now we have a single value for a single day, which is not cumulative counts but the total number of passengers that entered through this turnstile on this day.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_weeks(weekly_time_series):\n",
    "    combined = defaultdict(list)\n",
    "    \n",
    "    for week in weekly_time_series:\n",
    "        for turnstile,time_series in week.items():\n",
    "            combined[turnstile] += time_series\n",
    "            \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weekly_time_series' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1549b7bdb6b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcombined_time_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_weeks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweekly_time_series\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'weekly_time_series' is not defined"
     ]
    }
   ],
   "source": [
    "combined_time_series = combine_weeks(weekly_time_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_time_series' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ec8c41394745>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_time_series\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'combined_time_series' is not defined"
     ]
    }
   ],
   "source": [
    "list(combined_time_series.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_daily_time_series(combined_time_series):\n",
    "    turnstile_daily_time_series = {}\n",
    "    for i, (turnstile, time_series) in enumerate(combined_time_series.items()):\n",
    "        print('Processing turnstile', turnstile)\n",
    "        turnstile_daily_time_series(turnstile)= daily_calculation(time_series)\n",
    "        \n",
    "    return turnstile_daily_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "def count_within_normal_bounds(count):\n",
    "    if count is None:\n",
    "        return True\n",
    "    else:\n",
    "        return 10000>count >=0\n",
    "    \n",
    "def daily_calculation(time_series):\n",
    "    daily_time_series = []\n",
    "    \n",
    "    def day_of_timestamp(entry):\n",
    "        timestamp,tot_entries = entry\n",
    "        return timestamp.date()\n",
    "    \n",
    "    count_on_previous_day = None\n",
    "    for day,entries_on_this_day in groupby(time_series, key=day_of_timestamp):\n",
    "        cum_entry_count_on_day = max([count for time, count in entries_on_this_day])\n",
    "        \n",
    "        if count_on_previous_day is None:\n",
    "            daily_entries = None\n",
    "            \n",
    "        else:\n",
    "            daily_entries = cum_entry_count_on_day - count_on_previous_day\n",
    "            \n",
    "        count_on_previous_day = cum_entry_count_on_day\n",
    "        if count_within_normal_bounds(daily_entries):\n",
    "            daily_time_series.append((day, daily_entries))\n",
    "            \n",
    "        else:\n",
    "            print('Warning: Abnormal entry count found on day %s: %s' % (day, daily_entries))\n",
    "            daily_time_series.append((day, None))\n",
    "            \n",
    "    return daily_time_series\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "daily_time_series = convert_to_daily_time_series(combined_time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pprint(daily_time_series[('N090', 'R139', '01-06-00','CANAL ST')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "- We will plot the daily time series for a turnstile.\n",
    "\n",
    "In ipython notebook, add this to the beginning of your next cell:    \n",
    "\n",
    "    %matplotlib inline\n",
    "\n",
    "This will make your matplotlib graphs integrate nicely with the notebook.\n",
    "To plot the time series, import matplotlib with \n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "Take the list of [(date1, count1), (date2, count2), ...], for the turnstile and turn it into two lists:\n",
    "dates and counts. This should plot it:\n",
    "\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.plot(dates,counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "time_series = daily_time_series[('PTH11','R545','00-04-01','14Th STREET')]\n",
    "days, counts = zip(*time_series)\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(days,counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "- So far we've been operating on a single turnstile level, let's combine turnstiles in the same ControlArea/Unit/Station combo. There are some ControlArea/Unit/Station groups that have a single turnstile, but most have multiple turnstilea-- same value for the C/A, UNIT and STATION columns, different values for the SCP column.\n",
    "\n",
    "We want to combine the numbers together -- for each ControlArea/UNIT/STATION combo, for each day, add the counts from each turnstile belonging to that combo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def booth_of_item(item):\n",
    "    turnstile, time_series = item\n",
    "    control_area, unit, device_id, station = turnstile\n",
    "    return (control_area,unit,station)\n",
    "\n",
    "def reduce_to_booths(daily_time_series):\n",
    "    turnstile_time_series_items = sorted(daily_time_series.items())\n",
    "    booth_to_time_series ={}\n",
    "    \n",
    "    for booth, item_list_of_booth in groupby(turnstile_time_series_items, key=booth_of_item):\n",
    "        daily_counter = Counter()\n",
    "        \n",
    "        for turnstile, time_series in item_list_of_booth:\n",
    "            for day,count in time_series:\n",
    "                if count is not None:\n",
    "                    daily_counter[day] += count\n",
    "                    \n",
    "        booth_to_time_series[booth] = sorted(daily_counter.items())\n",
    "        \n",
    "    return booth_to_time_series\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "booth_series = reduce_to_booths(daily_time_series)\n",
    "pprint(booth_series[('PTH11','r545', '14TH STREET')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6\n",
    "- Similarly, combine everything in each station, and come up with a time series of `[(date1, count1),(date2,count2),...]` type of time series for each STATION, by adding up all the turnstiles in a station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def station_of_item(item):\n",
    "    turnstile, time_series = item\n",
    "    control_area, unit,station = booth\n",
    "    return (cstation)\n",
    "\n",
    "def reduce_to_station(booth_series):\n",
    "    booth_time_series_items = sorted(booth_series.items())\n",
    "    station_to_time_series ={}\n",
    "    \n",
    "    for station, item_list_of_station in groupby(booth_time_series_items, key=station_of_item):\n",
    "        daily_counter = Counter()\n",
    "        \n",
    "        for turnstile, time_series in item_list_of_station:\n",
    "            for day,count in time_series:\n",
    "                 daily_counter[day] += count\n",
    "                    \n",
    "        station_to_time_series[station] = sorted(daily_counter.items())\n",
    "        \n",
    "    return station_to_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "station_series = reduce_to_station(booth_series)\n",
    "pprint(station_series['14TH STREET'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7\n",
    "- Plot the time series for a station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_station(station_name,station_series):\n",
    "    time_series = station_series[station_name]\n",
    "    days,counts = zip(*time_series)\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(days,counts)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Number of turnstile entries')\n",
    "    plt.title('daily entries for station %s' % station_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_station('14TH STREET', station_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8\n",
    "- Make one list of counts for **one** week for one station. Monday's count, Tuesday's count, etc. so it's a list of 7 counts.\n",
    "Make the same list for another week, and another week, and another week.\n",
    "`plt.plot(week_count_list)` for every `week_count_list` you created this way. You should get a rainbow plot of weekly commute numbers on top of each other.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seperate_weeks(time_series):\n",
    "    time_series_for_each_week =[]\n",
    "    week = []\n",
    "    \n",
    "    for i,(day,count) in enumerate(time_series):\n",
    "        week.append((day,count))\n",
    "        \n",
    "        if i%7==6:\n",
    "            time_series_for_each_week.append(week)\n",
    "            week=[]\n",
    "            \n",
    "    time_series_for_each_week.append(week)\n",
    "    return time_series_for_each_week\n",
    "\n",
    "def rainbow_plot(station_name,station_series):\n",
    "    time_series = station_series[station_name]\n",
    "    time_series_for_each_week = seperate_weeks(time_series)\n",
    "    \n",
    "    plt.figure(figsize = (15,5))\n",
    "    for week in time_series_for_each_week:\n",
    "        days,counts = zip(*week)\n",
    "        days = range(len(counts))\n",
    "        plt.plot(days,counts)\n",
    "        \n",
    "    plt.xlabel('Day of week')\n",
    "    plt.ylabel('Number of turnstile entries')\n",
    "    plt.xticks(np.arrange(7),['St','Sn','Mo','Tu','We','Th','Fr'])\n",
    "    plt.title('Ridership per day for station %s' % station_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rainbow_plot['14TH STREET', station_series]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9\n",
    "- Over multiple weeks, sum total ridership for each station and sort them, so you can find out the stations with the highest traffic during the time you investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def station_total_traffic(item):\n",
    "    station,time_series = item\n",
    "    total = sum([count for day, count in time_series])\n",
    "    return total, station\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traffic_report = list(map(station_total_traffic, station_series.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for tot_traffic, station in sorted(traffic_report, reverse = True)[:30]:\n",
    "    print('%-18s %s' % (station, tot_traffic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 10\n",
    "- Make a single list of these total ridership values and plot it with `plt.hist(total_ridership_counts)` to get an idea about the distribution of total ridership among different stations.   \n",
    "This should show you that most stations have a small traffic, and the histogram bins for large traffic volumes have small bars.\n",
    "\n",
    "*Additional Hint*:    \n",
    "If you want to see which stations take the meat of the traffic, you can sort the total ridership counts and make a `plt.bar` graph. For this, you want to have two lists: the indices of each bar, and the values. The indices can just be `0,1,2,3,...`, so you can do \n",
    "\n",
    "    indices = range(len(total_ridership_values))\n",
    "    plt.bar(indices, total_ridership_values)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_ridership = [ridership for ridership, station in traffic_report]\n",
    "plt.figure(figsize=(15,5))\n",
    "hist = plt.hist(total_ridership,bins =20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "log_counts = []\n",
    "for count in total_ridership:\n",
    "    try:\n",
    "        log_result = math.log10(count)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    log_counts.append(log_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "n,bins,patches = hist = plt.hist(log_counts, bins = 15)\n",
    "def log_count_to_label(log_count):\n",
    "    if(log_count <= 6:\n",
    "        return '%0.f Thousand' % 10 == (log_count - 3)\n",
    "    else:\n",
    "       return '%.1f Million' % 10 * (log_count -6)\n",
    "       \n",
    "tick_labels = map(log_count_to_label, bins)\n",
    "ticks = plt.xticks(bins, tick_labels, rotaion = 70)\n",
    "plt.xlabel('Total ridership count')\n",
    "plt.ylabel('Number of stations')\n",
    "plt.title('Dist of ridership among NYC subway stations')\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_stations = sorted(traffic_report, reverse=True)[:30]\n",
    "counts, stations = zip(*top_stations)\n",
    "indices = range(len(counts))\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.bar(indices,counts)\n",
    "ticks = plt.xticks(indices, stations, rotation =70)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
